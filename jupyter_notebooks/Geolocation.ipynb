{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1b8f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "from constants import * #file with locations to replace\n",
    "from tqdm import tqdm\n",
    "import geograpy4\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bac5d10",
   "metadata": {},
   "source": [
    "## Replace or precise locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a952177",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = pd.read_csv(\"path\") #csv file with all locations from tweets and corresponding tweets ids\n",
    "locations = locations.dropna(subset=[\"place\"])\n",
    "locations = locations.reset_index().drop([\"index\"],axis=1)\n",
    "\n",
    "#Replace tweets fake locations by empty string and contractions by full location\n",
    "all_keys = list(replace_dict.keys())\n",
    "all_keys.sort(key=len)\n",
    "all_keys = all_keys[::-1]\n",
    "all_keys_lower = [x.lower() for x in all_keys]\n",
    "\n",
    "all_results = [replace_dict[x] for x in all_keys]\n",
    "\n",
    "new_locations = []\n",
    "for location in locations['place']:\n",
    "    new_loc_str = re.sub(\"{\", \"\" , location)\n",
    "    new_loc_str = re.sub(\"}\", \"\" , new_loc_str)\n",
    "    loc_lower = new_loc_str.lower()\n",
    "    for i, key in enumerate(all_keys_lower):\n",
    "        try:\n",
    "            p=re.compile(r\"\\b\"+key+r\"\\b\")\n",
    "            \n",
    "            m = p.search(loc_lower)\n",
    "            while m is not None :\n",
    "                span = m.span()\n",
    "                new_loc_str = new_loc_str[:span[0]]+ \\\n",
    "                        \"{\"+str(i)+\"}\" + \\\n",
    "                        new_loc_str[span[1]:]\n",
    "                loc_lower = new_loc_str.lower()\n",
    "                m = p.search(loc_lower)\n",
    "            \n",
    "            \n",
    "        except AttributeError:\n",
    "            continue\n",
    "    \n",
    "    new_loc_str = new_loc_str.format(*all_results)\n",
    "    new_locations.append(new_loc_str)\n",
    "\n",
    "new_locations_df = pd.DataFrame(new_locations)\n",
    "result = pd.concat([locations, new_locations_df], axis=1)\n",
    "result = result.drop([\"Unnamed: 0\"], axis=1)\n",
    "result.to_csv(\"path\") #export old locations with the new \"cleaned\" ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d6784b",
   "metadata": {},
   "source": [
    "## Precise locations with geograpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbcc59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=pd.read_parquet(r\"path_to_dataset\") #dataset with full tweets\n",
    "tweets=tweets.reset_index().drop([\"Unnamed: 0\",\"index\"],axis=1)\n",
    "#Create fields to store locations\n",
    "tweets[\"location\"]=\"\"\n",
    "tweets[\"latitude\"]=\"\"\n",
    "tweets[\"longitude\"]=\"\"\n",
    "\n",
    "list_location=tweets[\"user_location\"].value_counts()\n",
    "list_location=list_location[list_location>1]\n",
    "list_location=list(list_location.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091dd3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "places_to_geolocate=pd.read_csv(r\"path_csv_with_new_locations\")\n",
    "places_to_geolocate=places_to_geolocate.drop([\"Unnamed: 0\"], axis=1)\n",
    "places_to_geolocate[\"geograpy_output\"]=\"\"\n",
    "\n",
    "#Use geograpy to get place context of each user location we precised\n",
    "for i in tqdm(range(0,len(places_to_geolocate.index))):\n",
    "    try:\n",
    "        places_to_geolocate[\"geograpy_output\"][i] = geograpy4.get_place_context(places_to_geolocate[\"0\"][i])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "places_to_geolocate.geograpy_output = places_to_geolocate.geograpy_output.apply(lambda y: np.nan if len(y)==0 else y)\n",
    "places_to_geolocate=places_to_geolocate.dropna(subset=[\"geograpy_output\"]).reset_index().drop([\"index\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a428b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Allocate location longitude and latitude to corresponding location if full dataset\n",
    "for i in tqdm(range(0,len(places_to_geolocate.index))):\n",
    "    list_to_geolocate=tweets.index[tweets['user_location'] == places_to_geolocate[\"place\"][i]].tolist()\n",
    "    for j in list_to_geolocate:\n",
    "        tweets[\"location\"][j]=places_to_geolocate[\"geograpy_output\"][i][0][\"display_name\"]\n",
    "        tweets[\"latitude\"][j]=places_to_geolocate[\"geograpy_output\"][i][0][\"lat\"]\n",
    "        tweets[\"longitude\"][j]=places_to_geolocate[\"geograpy_output\"][i][0][\"lon\"]\n",
    "\n",
    "\n",
    "    \n",
    "tweets.location = tweets.location.apply(lambda y: np.nan if len(y)==0 else y)\n",
    "tweets=tweets.dropna(subset=[\"location\"]).reset_index().drop([\"index\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cafcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export new dataset with location, latitude and longitude\n",
    "tweets.to_csv(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
